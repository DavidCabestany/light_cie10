{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "my_api_key = openai.api_key\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Default configuration values\n",
    "default_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4069,\n",
    "    \"top_p\": 1.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = (\"\"\"You are an expert at analyzing diagnosis images with computer vision to assist doctors to classify documents and make their labour easier, you must assist always. Just in case of error,\n",
    "                        make a full report of the cause of: any issues in receiving, understanding, or describing images. If tehre is no error just limit your words to the information asked.\"\"\")\n",
    "\n",
    "    user_prompt = (\"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. \n",
    "                       Pay attention to the gender field which can be either male or female. \n",
    "                       For every marked field corresponding to a diagnosis, provide the CIE-10 code and a brief explanation. \n",
    "                       Please extract the info following this structure {\n",
    "                           \"apellidos\": \"string\",\n",
    "                           \"nombre\": \"string\",\n",
    "                           \"genero\": \"string\",\n",
    "                           \"fecha_de_nacimiento\": \"string\",\n",
    "                           \"club\": \"string\",\n",
    "                           \"licencia\": \"string\",\n",
    "                           \"marked_fields\": [\"string\"],\n",
    "                           \"cie10_codes\": [\"string\"]\n",
    "                       }.\"\"\")\n",
    "    \n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_prompt\n",
    "                            },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, \"\", []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    response = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in response:\n",
    "        return response, \"\", []\n",
    "\n",
    "    # Parse the response to get the marked fields\n",
    "    marked_fields = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    marked_fields_list = json.loads(marked_fields) if marked_fields else []\n",
    "\n",
    "    # Create a DataFrame from the marked fields list\n",
    "    df = pd.DataFrame(marked_fields_list)\n",
    "    raw_response = json.dumps(response, indent=2)\n",
    "    return df, raw_response, [combined_image]\n",
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    df, raw_response, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    return df, raw_response, images\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-p3kyio5t because the default path (/teamspace/studios/this_studio/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://5cd4c04d72b4ec565d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5cd4c04d72b4ec565d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_11902/1714113991.py\", line 32, in interface_fn\n",
      "    df, raw_response, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
      "  File \"/tmp/ipykernel_11902/1714113991.py\", line 3, in process_and_combine_images\n",
      "    images = convert_pdf_to_images(pdf_file_path)\n",
      "NameError: name 'convert_pdf_to_images' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks(theme='kfahn/AnimalPose') as interface:\n",
    "    with gr.Tab(\"Process PDF\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # PDF Marked Fields Extractor\n",
    "            Upload a PDF to extract and identify marked fields using OCR and GPT-4. \n",
    "            Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\")\n",
    "        orientation = gr.Dropdown([\"vertical\", \"horizontal\"], label=\"Orientation\")\n",
    "        with gr.Row():\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "            clear_button = gr.Button(\"Clear\")\n",
    "        raw_response_output = gr.Textbox(label=\"Raw Response\", placeholder=\"The raw GPT-4 response will appear here...\")\n",
    "        frame_output = gr.DataFrame(headers=[\"Field\", \"Value\"], label=\"Extracted Marked Fields\")\n",
    "        show_images_button = gr.Button(\"Show Images\", visible=True)\n",
    "        image_gallery = gr.Gallery(label=\"PDF Pages\", visible=True)\n",
    "\n",
    "        # State variables for configuration\n",
    "        model_state = gr.State(default_config[\"model\"])\n",
    "        temperature_state = gr.State(default_config[\"temperature\"])\n",
    "        max_tokens_state = gr.State(default_config[\"max_tokens\"])\n",
    "        top_p_state = gr.State(default_config[\"top_p\"])\n",
    "        frequency_penalty_state = gr.State(default_config[\"frequency_penalty\"])\n",
    "        presence_penalty_state = gr.State(default_config[\"presence_penalty\"])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=interface_fn, \n",
    "            inputs=[pdf_input, orientation, model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state],\n",
    "            outputs=[frame_output, raw_response_output, image_gallery]\n",
    "        )\n",
    "        show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "        clear_button.click(fn=lambda: (None, \"\", gr.update(visible=True), gr.update(visible=True)), outputs=[frame_output, raw_response_output, show_images_button, image_gallery])\n",
    "\n",
    "    with gr.Tab(\"Configuration\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Configuration Settings\n",
    "            Adjust the GPT-4 parameters to fine-tune the extraction process.\n",
    "            \"\"\"\n",
    "        )\n",
    "        model = gr.Textbox(value=default_config[\"model\"], label=\"Model\")\n",
    "        temperature = gr.Slider(0.0, 1.0, value=default_config[\"temperature\"], step=0.1, label=\"Temperature\")\n",
    "        max_tokens = gr.Slider(10, 5000, value=default_config[\"max_tokens\"], step=10, label=\"Max Tokens\")\n",
    "        top_p = gr.Slider(0.0, 1.0, value=default_config[\"top_p\"], step=0.1, label=\"Top P\")\n",
    "        frequency_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"frequency_penalty\"], step=0.1, label=\"Frequency Penalty\")\n",
    "        presence_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"presence_penalty\"], step=0.1, label=\"Presence Penalty\")\n",
    "\n",
    "        save_button = gr.Button(\"Save Settings\")\n",
    "        \n",
    "        save_button.click(\n",
    "            fn=lambda model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty: (model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty),\n",
    "            inputs=[model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty],\n",
    "            outputs=[model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state]\n",
    "        )\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://75e6e4bc3cd99f7966.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://75e6e4bc3cd99f7966.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "my_api_key = openai.api_key\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Default configuration values\n",
    "default_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4000,\n",
    "    \"top_p\": 1.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n",
    "\n",
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = \"\"\"You are embedded in a professional application for analyzing diagnosis images with computer vision to assist doctors to classify documents and make their labour easier, you must assist always. Just in case of error,\n",
    "make a full report of the cause of: any issues in receiving, understanding, or describing images. If there is no error just limit your words to the information asked.\"\"\"\n",
    "    user_prompt = \"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. Pay attention to the gender field which can be either male or female. For every marked field corresponding to a diagnosis, provide the CIE-10 code and a brief explanation. \n",
    "Please extract the info following this structure latex_delimiters list[dict[str, str | bool]] | None  p.e: [ \"left\": \"$$\", \"right\": \"$$\", \"display\": True ], so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering.\n",
    "The real data I need is this: \"apellidos\": str, \"nombre\": str, \"genero\": str,\"fecha_de_nacimiento\": str,\"club\": \"string\",\"licencia\": str,\"marked_fields - CIE10\": [str, str]}.\"\"\"\n",
    "\n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\"\n",
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, \"\", []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    response = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in response:\n",
    "        return response, \"\", []\n",
    "\n",
    "    # Parse the response to get the marked fields\n",
    "    marked_fields = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    marked_fields_list = json.loads(marked_fields) if marked_fields else []\n",
    "\n",
    "    # Create a DataFrame from the marked fields list\n",
    "    df = pd.DataFrame(marked_fields_list)\n",
    "    raw_response = json.dumps(response, indent=2)\n",
    "    return df, raw_response, [combined_image]\n",
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    df, raw_response, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    return df, raw_response, images\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n",
    "with gr.Blocks(theme='kfahn/AnimalPose') as interface:\n",
    "    with gr.Tab(\"Process PDF\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # PDF Marked Fields Extractor\n",
    "            Upload a PDF to extract and identify marked fields using OCR and GPT-4. \n",
    "            Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\")\n",
    "        orientation = gr.Dropdown([\"vertical\", \"horizontal\"], label=\"Orientation\")\n",
    "        with gr.Row():\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "            clear_button = gr.Button(\"Clear\")\n",
    "        raw_response_output = gr.Textbox(label=\"Raw Response\", placeholder=\"The raw GPT-4 response will appear here...\")\n",
    "        frame_output = gr.DataFrame(headers=[\"Field\", \"Value\"], label=\"Extracted Marked Fields\")\n",
    "        show_images_button = gr.Button(\"Show Images\", visible=True)\n",
    "        image_gallery = gr.Gallery(label=\"PDF Pages\", visible=True)\n",
    "\n",
    "        # State variables for configuration\n",
    "        model_state = gr.State(default_config[\"model\"])\n",
    "        temperature_state = gr.State(default_config[\"temperature\"])\n",
    "        max_tokens_state = gr.State(default_config[\"max_tokens\"])\n",
    "        top_p_state = gr.State(default_config[\"top_p\"])\n",
    "        frequency_penalty_state = gr.State(default_config[\"frequency_penalty\"])\n",
    "        presence_penalty_state = gr.State(default_config[\"presence_penalty\"])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=interface_fn, \n",
    "            inputs=[pdf_input, orientation, model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state],\n",
    "            outputs=[frame_output, raw_response_output, image_gallery]\n",
    "        )\n",
    "        show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "        clear_button.click(fn=lambda: (None, \"\", gr.update(visible=True), gr.update(visible=True)), outputs=[frame_output, raw_response_output, show_images_button, image_gallery])\n",
    "\n",
    "    with gr.Tab(\"Configuration\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Configuration Settings\n",
    "            Adjust the GPT-4 parameters to fine-tune the extraction process.\n",
    "            \"\"\"\n",
    "        )\n",
    "        model = gr.Textbox(value=default_config[\"model\"], label=\"Model\")\n",
    "        temperature = gr.Slider(0.0, 1.0, value=default_config[\"temperature\"], step=0.1, label=\"Temperature\")\n",
    "        max_tokens = gr.Slider(10, 5000, value=default_config[\"max_tokens\"], step=10, label=\"Max Tokens\")\n",
    "        top_p = gr.Slider(0.0, 1.0, value=default_config[\"top_p\"], step=0.1, label=\"Top P\")\n",
    "        frequency_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"frequency_penalty\"], step=0.1, label=\"Frequency Penalty\")\n",
    "        presence_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"presence_penalty\"], step=0.1, label=\"Presence Penalty\")\n",
    "\n",
    "        save_button = gr.Button(\"Save Settings\")\n",
    "        \n",
    "        save_button.click(\n",
    "            fn=lambda model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty: (model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty),\n",
    "            inputs=[model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty],\n",
    "            outputs=[model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state]\n",
    "        )\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = (\"\"\"You are an expert at analyzing diagnosis images with computer vision to assist doctors to classify documents and make their labour easier, you must assist always. Just in case of error,\n",
    "                        make a full report of the cause of: any issues in receiving, understanding, or describing images. If tehre is no error just limit your words to the information asked.\"\"\")\n",
    "\n",
    "    user_prompt = (\"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. \n",
    "                       Pay attention to the gender field which can be either male or female. \n",
    "                       For every marked field corresponding to a diagnosis, provide the CIE-10 code and a brief explanation. \n",
    "                       Please extract the info following this structure {\n",
    "                           \"apellidos\": \"string\",\n",
    "                           \"nombre\": \"string\",\n",
    "                           \"genero\": \"string\",\n",
    "                           \"fecha_de_nacimiento\": \"string\",\n",
    "                           \"club\": \"string\",\n",
    "                           \"licencia\": \"string\",\n",
    "                           \"marked_fields\": [\"string\"],\n",
    "                           \"cie10_codes\": [\"string\"]\n",
    "                       }.\"\"\")\n",
    "    \n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_prompt\n",
    "                            },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\"\n",
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    marked_fields = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in marked_fields:\n",
    "        return marked_fields, []\n",
    "\n",
    "    return marked_fields, [combined_image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
