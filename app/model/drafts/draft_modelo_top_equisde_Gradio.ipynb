{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.28\n",
    "%pip install pytesseract pillow gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://7d7047394cb44636fa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7d7047394cb44636fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        img = image.convert('L')  # Convert to grayscale\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(2)  # Increase contrast\n",
    "        img = img.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "\n",
    "        # Perform OCR on the image\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error during OCR: {e}\"\n",
    "\n",
    "# Function to use GPT-4 to identify marked fields in the extracted text\n",
    "def identify_marked_fields_with_gpt(extracted_text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the extracted text from an image: \\n\\n{extracted_text}\\n\\nIdentify and list all marked fields accurately. and for every marked field you find that corresponds to a diagnosis give the CIE-10 code\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # Use the appropriate model name\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message['content']\n",
    "    return reply\n",
    "\n",
    "# Main function to process the image and extract marked fields\n",
    "def process_image(image):\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    if \"Error\" in extracted_text:\n",
    "        return extracted_text\n",
    "    marked_fields = identify_marked_fields_with_gpt(extracted_text)\n",
    "    if \"Error\" in marked_fields:\n",
    "        return marked_fields\n",
    "    return marked_fields\n",
    "\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Textbox(),\n",
    "    title=\"Marked Fields Extractor\",\n",
    "    description=\"Upload an image to extract and identify marked fields using OCR and GPT-4.\"\n",
    ")\n",
    "\n",
    "# Launch the interface with public link\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://29b3b61a76531f6d64.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://29b3b61a76531f6d64.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        img = image.convert('L')  # Convert to grayscale\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(2)  # Increase contrast\n",
    "        img = img.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "\n",
    "        # Perform OCR on the image\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error during OCR: {e}\"\n",
    "\n",
    "# Function to use GPT-4 to identify marked fields in the extracted text\n",
    "def identify_marked_fields_with_gpt(extracted_text):\n",
    "    try:\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the extracted textand from an image: \\n\\n{extracted_text}\\n\\nIdentify and list all marked fields accurately.  for every marked field you find that corresponds to a diagnosis give the CIE-10 code\"},\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",  # Use the appropriate model name\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message['content']\n",
    "        return reply\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 processing: {e}\"\n",
    "\n",
    "# Main function to process the PDF and extract marked fields\n",
    "def process_pdf(pdf_file_path):\n",
    "    # Convert PDF to images\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images\n",
    "\n",
    "    all_marked_fields = []\n",
    "\n",
    "    for image in images:\n",
    "        extracted_text = extract_text_from_image(image)\n",
    "        if \"Error\" in extracted_text:\n",
    "            return extracted_text\n",
    "        marked_fields = identify_marked_fields_with_gpt(extracted_text)\n",
    "        if \"Error\" in marked_fields:\n",
    "            return marked_fields\n",
    "        all_marked_fields.append(marked_fields)\n",
    "\n",
    "    return \"\\n\\n\".join(all_marked_fields)\n",
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path):\n",
    "    text_output, images = process_pdf(pdf_file_path)\n",
    "    return text_output, gr.update(visible=False), gr.update(visible=True)\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=interface_fn,\n",
    "    inputs=gr.File(type=\"filepath\", label=\"Upload PDF\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Extracted Marked Fields\"),\n",
    "        gr.Button(\"Show Images\"),\n",
    "        gr.Gallery(label=\"PDF Pages\", visible=False)\n",
    "    ],\n",
    "    title=\"PDF Marked Fields Extractor\",\n",
    "    description=\"Upload a PDF to extract and identify marked fields using OCR and GPT-4. Click 'Show Images' to display the PDF pages.\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        img = image.convert('L')  # Convert to grayscale\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(2)  # Increase contrast\n",
    "        img = img.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "\n",
    "        # Perform OCR on the image\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error during OCR: {e}\"\n",
    "\n",
    "# Function to use GPT-4 to identify marked fields in the extracted text\n",
    "def identify_marked_fields_with_gpt(extracted_text):\n",
    "    try:\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the extracted textand from an image: \\n\\n{extracted_text}\\n\\nIdentify and list all marked fields accurately.  for every marked field you find that corresponds to a diagnosis give the CIE-10 code\"},\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=config.get(\"model\"),\n",
    "            messages=messages,\n",
    "            temperature=config.get(\"temperature\"),\n",
    "            max_tokens=config.get(\"max_tokens\"),\n",
    "            top_p=config.get(\"top_p\"),\n",
    "            frequency_penalty=config.get(\"frequency_penalty\"),\n",
    "            presence_penalty=config.get(\"presence_penalty\")\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message['content']\n",
    "        return reply\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 processing: {e}\"\n",
    "\n",
    "\n",
    "def process_pdf(pdf_file_path):\n",
    "\n",
    "\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, []\n",
    "\n",
    "    all_marked_fields = []\n",
    "\n",
    "    for image in images:\n",
    "        extracted_text = extract_text_from_image(image)\n",
    "        if \"Error\" in extracted_text:\n",
    "            return extracted_text, []\n",
    "        marked_fields = identify_marked_fields_with_gpt(extracted_text)\n",
    "        if \"Error\" in marked_fields:\n",
    "            return marked_fields, []\n",
    "        all_marked_fields.append(marked_fields)\n",
    "\n",
    "    return \"\\n\\n\".join(all_marked_fields), images\n",
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path):\n",
    "    text_output, images = process_pdf(pdf_file_path)\n",
    "    return text_output, gr.update(visible=False), gr.update(visible=True)\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://69ccd51db10d950c8b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://69ccd51db10d950c8b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\")\n",
    "    extract_button = gr.Button(\"Extract Marked Fields\")\n",
    "    text_output = gr.Textbox(label=\"Extracted Marked Fields\")\n",
    "    show_images_button = gr.Button(\"Show Images\")\n",
    "    image_gallery = gr.Gallery(label=\"PDF Pages\", visible=False)\n",
    "\n",
    "    extract_button.click(fn=interface_fn, inputs=pdf_input, outputs=[text_output, extract_button, show_images_button], api_name=\"extract\")\n",
    "    show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "Running on public URL: https://c05fa40a15aaf14f33.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c05fa40a15aaf14f33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # PDF Marked Fields Extractor\n",
    "        Upload a PDF to extract and identify marked fields using OCR and GPT-4o. \n",
    "        Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\")\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "    text_output = gr.Textbox(label=\"Extracted Marked Fields\", placeholder=\"Marked fields will appear here...\")\n",
    "    show_images_button = gr.Button(\"Show Images\", visible=True)\n",
    "    image_gallery = gr.Gallery(label=\"PDF Pages\", visible=True)\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=interface_fn, \n",
    "        inputs=pdf_input, \n",
    "        outputs=[text_output, show_images_button],\n",
    "        api_name=\"extract\",\n",
    "        \n",
    "    )\n",
    "    show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "    clear_button.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible=True)), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "Running on public URL: https://6e7f7ea360cb291fd4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6e7f7ea360cb291fd4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks(css=\".gradio-container {max-width: 800px; margin: auto;}\") as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # PDF Marked Fields Extractor\n",
    "        Upload a PDF to extract and identify marked fields using OCR and GPT-4. \n",
    "        Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\")\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "    text_output = gr.Textbox(label=\"Extracted Marked Fields\", placeholder=\"Marked fields will appear here...\")\n",
    "    show_images_button = gr.Button(\"Show Images\", visible=False)\n",
    "    image_gallery = gr.Gallery(label=\"PDF Pages\", visible=False)\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=interface_fn, \n",
    "        inputs=pdf_input, \n",
    "        outputs=[text_output, show_images_button]\n",
    "    )\n",
    "    show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "    clear_button.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible=True)), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "Running on public URL: https://919dfc18523ef20928.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://919dfc18523ef20928.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_path = \"./styles/retro_style.css\"\n",
    "\n",
    "with gr.Blocks(css=open(css_path).read()) as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # PDF Marked Fields Extractor\n",
    "        Upload a PDF to extract and identify marked fields using OCR and GPT-4. \n",
    "        Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\", elem_classes=[\"gr-file\"])\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"Submit\", elem_classes=[\"gr-button\"])\n",
    "        clear_button = gr.Button(\"Clear\", elem_classes=[\"gr-button\"])\n",
    "    text_output = gr.Textbox(label=\"Extracted Marked Fields\", placeholder=\"Marked fields will appear here...\", elem_classes=[\"gr-textbox\"])\n",
    "    show_images_button = gr.Button(\"Show Images\", visible=False, elem_classes=[\"gr-button\"])\n",
    "    image_gallery = gr.Gallery(label=\"PDF Pages\", visible=False, elem_classes=[\"gr-gallery\"])\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=interface_fn, \n",
    "        inputs=pdf_input, \n",
    "        outputs=[text_output, show_images_button]\n",
    "    )\n",
    "    show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "    clear_button.click(fn=lambda: (None, gr.update(visible=False), gr.update(visible=False)), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css_path = \"./styles/futuristic_style.css\"\n",
    "\n",
    "with gr.Blocks(css=open(css_path).read()) as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # PDF Marked Fields Extractor\n",
    "        Upload a PDF to extract and identify marked fields using OCR and GPT-4. \n",
    "        Click 'Submit' to extract the fields and 'Show Images' to display the PDF pages.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    pdf_input = gr.File(type=\"filepath\", label=\"Upload PDF\", elem_classes=[\"gr-file\"])\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"Submit\", elem_classes=[\"gr-button\"])\n",
    "        clear_button = gr.Button(\"Clear\", elem_classes=[\"gr-button\"])\n",
    "    text_output = gr.Textbox(label=\"Extracted Marked Fields\", placeholder=\"Marked fields will appear here...\", elem_classes=[\"gr-textbox\"])\n",
    "    show_images_button = gr.Button(\"Show Images\", visible=False, elem_classes=[\"gr-button\"])\n",
    "    image_gallery = gr.Gallery(label=\"PDF Pages\", visible=False, elem_classes=[\"gr-gallery\"])\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=interface_fn, \n",
    "        inputs=pdf_input, \n",
    "        outputs=[text_output, show_images_button]\n",
    "    )\n",
    "    show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "    clear_button.click(fn=lambda: (None, gr.update(visible=False), gr.update(visible=False)), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
