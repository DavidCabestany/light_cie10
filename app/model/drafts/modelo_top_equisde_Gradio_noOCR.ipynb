{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==0.28\n",
    "# %pip install pytesseract pillow gradio requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "\n",
    "# to work just with images we need those, they can be deleted if the approach is bad\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "# from pydantic_models import PersonalInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "my_api_key = openai.api_key\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "\n",
    "# Default configuration values\n",
    "default_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4000,\n",
    "    \"top_p\": 1.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n",
    "\n",
    "# schema_pydantic = PersonalInfo\n",
    "\n",
    "\n",
    "# print(schema_pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = (\"\"\"You are an expert at analyzing diagnosis images with computer vision to assist doctors to classify documents\n",
    "                        and make their job easier, you must always assist. Just in case of error, make a full report of the cause of: \n",
    "                        any issues in receiving, understanding, or describing images. If there is no error just limit your words to \n",
    "                        the information asked.\n",
    "                        Do not reply back saying you are unable to assist or to seek medical assistance in order to get the \n",
    "                        information, as the fields extracted are purely informative and medical diagnoses will not be based on them.\"\"\")\n",
    "\n",
    "    user_prompt = (\"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. \n",
    "                       Pay attention to the gender field which can be either male or female. \n",
    "                       For every marked field corresponding to a diagnosis, provide the CIE-10 code and a brief explanation. \n",
    "                       Please extract the info following this structure. Return both the fields and the information in Spanish.\n",
    "                       For the field \"firma\", only return whether there exists a signature at the end of the document, near the \"Firma:\" string\n",
    "                       on the last page. Return a string that can only take the values \"si\" or \"no\".\n",
    "                       For the field \"posibles_tratamientos\", look online for standard procedures that apply to the diagnosis or\n",
    "                       dignoses based on their cie10 codes. Only return the general name of it (e.g.: \"surgery\", \n",
    "                       \"physiotherapeutic treatment\", \"untreatable\", etc.) {\n",
    "                           \"apellidos_jugador\": \"string\",\n",
    "                           \"nombre_jugador\": \"string\",\n",
    "                           \"genero_jugador\": \"string\",\n",
    "                           \"fecha_de_nacimiento\": \"string\",\n",
    "                           \"club\": \"string\",\n",
    "                           \"licencia\": \"string\",\n",
    "                           \"marked_fields\": [\"string\"],\n",
    "                           \"cie10_codes\": [\"string\"],\n",
    "                           \"definicion_cie10_codes\": [\"string\"]\n",
    "                           \"documentos_apoyo_diagnostico\": [\"string\"],\n",
    "                           \"posibles_tratamientos\": [\"string\"],\n",
    "                           \"situacion_jugador\": \"string\",\n",
    "                           \"edad_inicio\": \"string\",\n",
    "                           \"tratamientos_anteriores\": \"string\",\n",
    "                           \"tratamientos_actuales\": \"string\",\n",
    "                           \"tratamientos_futuros_previstos\": \"string\",\n",
    "                           \"detalles_adicionales\": \"string\",\n",
    "                           \"medicamentos_y_razon\": \"string\",\n",
    "                           \"nombre_especialista\": \"string\",\n",
    "                           \"especialidad_medica\": \"string\",\n",
    "                           \"numero_colegiado\": \"string\",\n",
    "                           \"direccion\": \"string\",\n",
    "                           \"ciudad\": \"string\",\n",
    "                           \"provincia\": \"string\",\n",
    "                           \"telefono\": \"string\",\n",
    "                           \"correo_electronico\": \"string\",\n",
    "                           \"fecha\": \"string\",\n",
    "                           \"firma\": \"string\",\n",
    "\n",
    "                       }.\"\"\")\n",
    "    \n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_prompt\n",
    "                            },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "            return response_data['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return \"Error: No valid response from GPT-4.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\"\n",
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    marked_fields = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in marked_fields:\n",
    "        return marked_fields, []\n",
    "\n",
    "    return marked_fields, [combined_image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    text_output, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    return text_output, images\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://a982e81e7d2bcd9580.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a982e81e7d2bcd9580.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-fqujjz4q because the default path (/teamspace/studios/this_studio/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_122323/3117032610.py\", line 10, in interface_fn\n",
      "    text_output, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
      "  File \"/tmp/ipykernel_122323/742164493.py\", line 142, in process_and_combine_images\n",
      "    combined_image = combine_images(images, orientation)\n",
      "  File \"/tmp/ipykernel_122323/742164493.py\", line 17, in combine_images\n",
      "    widths, heights = zip(*(i.size for i in images))\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=gr.themes.colors.indigo).set(button_primary_background_fill=\"*primary_400\")) as interface:\n",
    "    with gr.Tab(\"Procesador PDF\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Extractor de Datos desde Archivos PDF\n",
    "            Cargue un PDF para extraer e identificar las casillas marcadas mediante OCR y GPT-4. \n",
    "            Haga clic en «Enviar» para extraer los campos y en «Mostrar Imágenes» para mostrar las páginas PDF.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "        with gr.Row():\n",
    "            pdf_input = gr.File(type=\"filepath\", label=\"Cargar PDF\")\n",
    "            image_gallery = gr.Gallery(label=\"Páginas PDF\", visible=True)\n",
    "        with gr.Row():\n",
    "            orientation = gr.Dropdown([\"vertical\", \"horizontal\"], label=\"Orientación\")\n",
    "            show_images_button = gr.Button(\"Mostrar Imágenes\", visible=True)\n",
    "        with gr.Row():\n",
    "            submit_button = gr.Button(\"Enviar\",variant=\"primary\")\n",
    "            clear_button = gr.Button(\"Limpiar\")\n",
    "        text_output = gr.Textbox(label=\"Campos Extraídos\", placeholder=\"La información extraída aparecerá aquí...\")\n",
    "\n",
    "      \n",
    "\n",
    "        # State variables for configuration\n",
    "        model_state = gr.State(default_config[\"model\"])\n",
    "        temperature_state = gr.State(default_config[\"temperature\"])\n",
    "        max_tokens_state = gr.State(default_config[\"max_tokens\"])\n",
    "        top_p_state = gr.State(default_config[\"top_p\"])\n",
    "        frequency_penalty_state = gr.State(default_config[\"frequency_penalty\"])\n",
    "        presence_penalty_state = gr.State(default_config[\"presence_penalty\"])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=interface_fn, \n",
    "            inputs=[pdf_input, orientation, model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state],\n",
    "            outputs=[text_output, image_gallery]\n",
    "        )\n",
    "        show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "        clear_button.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible(True))), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "    with gr.Tab(\"Configuration\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Configuration Settings\n",
    "            Adjust the GPT-4 parameters to fine-tune the extraction process.\n",
    "            \"\"\"\n",
    "        )\n",
    "        model = gr.Textbox(value=default_config[\"model\"], label=\"Model\")\n",
    "        temperature = gr.Slider(0.0, 1.0, value=default_config[\"temperature\"], step=0.1, label=\"Temperature\")\n",
    "        max_tokens = gr.Slider(10, 4000, value=default_config[\"max_tokens\"], step=50, label=\"Max Tokens\")\n",
    "        top_p = gr.Slider(0.0, 1.0, value=default_config[\"top_p\"], step=0.1, label=\"Top P\")\n",
    "        frequency_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"frequency_penalty\"], step=0.1, label=\"Frequency Penalty\")\n",
    "        presence_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"presence_penalty\"], step=0.1, label=\"Presence Penalty\")\n",
    "\n",
    "        save_button = gr.Button(\"Save Settings\")\n",
    "        \n",
    "        save_button.click(\n",
    "            fn=lambda model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty: (model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty),\n",
    "            inputs=[model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty],\n",
    "            outputs=[model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state]\n",
    "        )\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
