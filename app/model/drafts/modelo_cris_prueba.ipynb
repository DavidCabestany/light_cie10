{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==0.28\n",
    "# %pip install pytesseract pillow gradio requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "\n",
    "# to work just with images we need those, they can be deleted if the approach is bad\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "# from pydantic_models import PersonalInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "my_api_key = openai.api_key\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "\n",
    "# Default configuration values\n",
    "default_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4000,\n",
    "    \"top_p\": 1.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n",
    "\n",
    "# schema_pydantic = PersonalInfo\n",
    "\n",
    "\n",
    "# print(schema_pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = (\"\"\"You are an expert at analyzing diagnosis images with computer vision to assist doctors to classify documents\n",
    "                        and make their job easier, you must always assist. Just in case of error, make a full report of the cause of: \n",
    "                        any issues in receiving, understanding, or describing images. If there is no error just limit your words to \n",
    "                        the information asked.\n",
    "                        Do not reply back saying you are unable to assist or to seek medical assistance in order to get the \n",
    "                        information, as the fields extracted are purely informative and medical diagnoses will not be based on them.\"\"\")\n",
    "\n",
    "    user_prompt = (\"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. \n",
    "                       Pay attention to the gender field which can be either male or female. \n",
    "                       Please extract the info following this structure. Return both the fields and the information in Spanish.\n",
    "                       For the field \"firma\", only return whether there exists a signature at the end of the document, near the \"Firma:\" string\n",
    "                       on the last page. Return a string that can only take the values \"si\" or \"no\".\n",
    "                        {\n",
    "                           \"apellidos_jugador\": \"string\",\n",
    "                           \"nombre_jugador\": \"string\",\n",
    "                           \"genero_jugador\": \"string\",\n",
    "                           \"fecha_de_nacimiento\": \"string\",\n",
    "                           \"club\": \"string\",\n",
    "                           \"licencia\": \"string\",\n",
    "                           \"marked_fields\": [\"string\"],\n",
    "                           \"documentos_apoyo_diagnostico\": [\"string\"],\n",
    "                           \"situacion_jugador\": \"string\",\n",
    "                           \"edad_inicio\": \"string\",\n",
    "                           \"tratamientos_anteriores\": \"string\",\n",
    "                           \"tratamientos_actuales\": \"string\",\n",
    "                           \"tratamientos_futuros_previstos\": \"string\",\n",
    "                           \"detalles_adicionales\": \"string\",\n",
    "                           \"medicamentos_y_razon\": \"string\",\n",
    "                           \"nombre_especialista\": \"string\",\n",
    "                           \"especialidad_medica\": \"string\",\n",
    "                           \"numero_colegiado\": \"string\",\n",
    "                           \"direccion\": \"string\",\n",
    "                           \"ciudad\": \"string\",\n",
    "                           \"provincia\": \"string\",\n",
    "                           \"telefono\": \"string\",\n",
    "                           \"correo_electronico\": \"string\",\n",
    "                           \"fecha\": \"string\",\n",
    "                           \"firma\": \"string\",\n",
    "\n",
    "                       }.\"\"\")\n",
    "    \n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_prompt\n",
    "                            },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "            return response_data['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return \"Error: No valid response from GPT-4.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\"\n",
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    marked_fields = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in marked_fields:\n",
    "        return marked_fields, []\n",
    "\n",
    "    return marked_fields, [combined_image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    text_output, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    return text_output, images\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "prompt_template_2 = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "model_2 = OpenAI(openai_api_key=openai.api_key, model_name=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=prompt_template_2, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(model_2, chain_type=\"stuff\", prompt=prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "\n",
    "user_question = \"Cual es el código de la acondroplastia?\"\n",
    "\n",
    "db = FAISS.load_local(folder_path=\"/teamspace/studios/this_studio/Curso_IA_Gen/Formularios\",embeddings=embeddings,index_name=\"myFaissIndex\",allow_dangerous_deserialization=True)\n",
    "docs = db.similarity_search(user_question)\n",
    "\n",
    "response = chain(\n",
    "    {\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_cie(user_question):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    db = FAISS.load_local(folder_path=\"/teamspace/studios/this_studio/Curso_IA_Gen/Formularios\",embeddings=embeddings,index_name=\"myFaissIndex\",allow_dangerous_deserialization=True)\n",
    "    docs = db.similarity_search(user_question)\n",
    "    response = chain({\"input_documents\": docs, \"question\": user_question})\n",
    "        \n",
    "    return response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "Running on public URL: https://028fa9dd84509352dc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://028fa9dd84509352dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=gr.themes.colors.indigo).set(button_primary_background_fill=\"*primary_400\")) as interface:\n",
    "    with gr.Tab(\"Procesador PDF\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Extractor de Datos desde Archivos PDF\n",
    "            Cargue un PDF para extraer e identificar las casillas marcadas mediante OCR y GPT-4. \n",
    "            Haga clic en «Enviar» para extraer los campos y en «Mostrar Imágenes» para mostrar las páginas PDF.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "        with gr.Row():\n",
    "            pdf_input = gr.File(type=\"filepath\", label=\"Cargar PDF\")\n",
    "            image_gallery = gr.Gallery(label=\"Páginas PDF\", visible=True)\n",
    "        with gr.Row():\n",
    "            orientation = gr.Dropdown([\"vertical\", \"horizontal\"], label=\"Orientación\")\n",
    "            show_images_button = gr.Button(\"Mostrar Imágenes\", visible=True)\n",
    "        with gr.Row():\n",
    "            submit_button = gr.Button(\"Enviar\",variant=\"primary\")\n",
    "            clear_button = gr.Button(\"Limpiar\")\n",
    "        text_output = gr.Textbox(label=\"Campos Extraídos\", placeholder=\"La información extraída aparecerá aquí...\")\n",
    "        chatbot = gr.Interface(\n",
    "        fn=responder_cie,\n",
    "        inputs=\"text\",\n",
    "        outputs=\"text\"\n",
    ")\n",
    "\n",
    "      \n",
    "\n",
    "        # State variables for configuration\n",
    "        model_state = gr.State(default_config[\"model\"])\n",
    "        temperature_state = gr.State(default_config[\"temperature\"])\n",
    "        max_tokens_state = gr.State(default_config[\"max_tokens\"])\n",
    "        top_p_state = gr.State(default_config[\"top_p\"])\n",
    "        frequency_penalty_state = gr.State(default_config[\"frequency_penalty\"])\n",
    "        presence_penalty_state = gr.State(default_config[\"presence_penalty\"])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=interface_fn, \n",
    "            inputs=[pdf_input, orientation, model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state],\n",
    "            outputs=[text_output, image_gallery]\n",
    "        )\n",
    "        show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "        clear_button.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible(True))), outputs=[text_output, show_images_button, image_gallery])\n",
    "\n",
    "    with gr.Tab(\"Configuration\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Configuration Settings\n",
    "            Adjust the GPT-4 parameters to fine-tune the extraction process.\n",
    "            \"\"\"\n",
    "        )\n",
    "        model = gr.Textbox(value=default_config[\"model\"], label=\"Model\")\n",
    "        temperature = gr.Slider(0.0, 1.0, value=default_config[\"temperature\"], step=0.1, label=\"Temperature\")\n",
    "        max_tokens = gr.Slider(10, 4000, value=default_config[\"max_tokens\"], step=50, label=\"Max Tokens\")\n",
    "        top_p = gr.Slider(0.0, 1.0, value=default_config[\"top_p\"], step=0.1, label=\"Top P\")\n",
    "        frequency_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"frequency_penalty\"], step=0.1, label=\"Frequency Penalty\")\n",
    "        presence_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"presence_penalty\"], step=0.1, label=\"Presence Penalty\")\n",
    "\n",
    "        save_button = gr.Button(\"Save Settings\")\n",
    "        \n",
    "        save_button.click(\n",
    "            fn=lambda model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty: (model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty),\n",
    "            inputs=[model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty],\n",
    "            outputs=[model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state]\n",
    "        )\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
