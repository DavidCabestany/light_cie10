{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import fitz # PyMuPDF\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# to work just with images we need those, they can be deleted if the approach is bad\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "# from pydantic_models import PersonalInfo\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# Load environment variables from a .env file\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "my_api_key = openai.api_key\n",
    "with open('./app/model/configs/gpt_config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Default configuration values\n",
    "default_config = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4000,\n",
    "    \"top_p\": 1.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n",
    "\n",
    "# Function to convert PDF to images using PyMuPDF\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            images.append(img)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        return f\"Error during PDF conversion: {e}\"\n",
    "\n",
    "# Function to combine images into a single image\n",
    "def combine_images(images, orientation='vertical'):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    if orientation == 'vertical':\n",
    "        total_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        y_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (0, y_offset))\n",
    "            y_offset += img.height\n",
    "    else:\n",
    "        total_width = sum(widths)\n",
    "        total_height = max(heights)\n",
    "        combined_image = Image.new('RGB', (total_width, total_height))\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to send combined image to GPT-4\n",
    "def send_image_to_gpt(image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    system_prompt = (\"\"\"You are an expert at analyzing diagnosis images with computer vision to assist doctors to classify documents\n",
    "                        and make their job easier, you must always assist. Just in case of error, make a full report of the cause of: \n",
    "                        any issues in receiving, understanding, or describing images. If there is no error just limit your words to \n",
    "                        the information asked.\n",
    "                        Do not reply back saying you are unable to assist or to seek medical assistance in order to get the \n",
    "                        information, as the fields extracted are purely informative and medical diagnoses will not be based on them.\"\"\")\n",
    "\n",
    "    user_prompt = (\"\"\"Identify and list all marked fields accurately and provide a table with the personal data you might find. \n",
    "                       Pay attention to the gender field which can be either male or female. \n",
    "                       For the field \"firma\", only return whether there exists a signature at the end of the document, near the \"Firma:\" string\n",
    "                       on the last page. Return a string that can only take the values \"si\" or \"no\".\n",
    "                       For the field \"sugerencia_tratamientos\", look online for standard procedures that apply to the diagnosis or\n",
    "                       dignoses based on their cie-10 codes. Only return the general name of it (e.g.: \"surgery\", \n",
    "                       \"physiotherapeutic treatment\", \"untreatable\", etc.) for 'tratamiento', and in 'explicacion', explain them in greater detail.\n",
    "                       For the field \"sugerencia_farmacos\", return some examples of medicines commonly used to treat the condition based on its\n",
    "                       cie-10 codes, if it applies, based in the most recent edition of Vademecum you have access to. In 'farmaco' only return the name of the medicine or medicines, \n",
    "                       and in 'efecto' write down the effect of them.\n",
    "                       For the field \"sugerencia_revision\", return how often the patient should have a medical checkup to evaluate its\n",
    "                       diagnosis or diagnoses based on the cie-10 code.\n",
    "                       For the cie-10 codes, if the condition is vague give all the codes that apply to each condition, \n",
    "                       and also the description given in the oficial cie-10 in Spanish.\n",
    "                       Do not include \"```json\" or \"```\" at the start or end of the response. It must start with { and end with }, with no \n",
    "                       extra text. If you cannot find a specific field, return it as null.\n",
    "                       Please extract the info following this structure. Return both the fields and the information in Spanish:\n",
    "                        {\n",
    "                           \"apellidos_jugador\": \"string\",\n",
    "                           \"nombre_jugador\": \"string\",\n",
    "                           \"genero_jugador\": \"string\",\n",
    "                           \"fecha_de_nacimiento\": \"string\",\n",
    "                           \"club\": \"string\",\n",
    "                           \"licencia\": \"string\",\n",
    "                           \"marked_fields\": [\"string\"],\n",
    "                           \"Codigo_CIE\":[condicion: \"string\", descripcion: \"string\"],\n",
    "                           \"documentos_apoyo_diagnostico\": [\"string\"],\n",
    "                           \"situacion_jugador\": \"string\",\n",
    "                           \"edad_inicio\": \"string\",\n",
    "                           \"tratamientos_anteriores\": \"string\",\n",
    "                           \"tratamientos_actuales\": \"string\",\n",
    "                           \"tratamientos_futuros_previstos\": \"string\",\n",
    "                           \"detalles_adicionales\": \"string\",\n",
    "                           \"medicamentos_y_razon\": \"string\",\n",
    "                           \"nombre_especialista\": \"string\",\n",
    "                           \"especialidad_medica\": \"string\",\n",
    "                           \"numero_colegiado\": \"string\",\n",
    "                           \"direccion\": \"string\",\n",
    "                           \"ciudad\": \"string\",\n",
    "                           \"provincia\": \"string\",\n",
    "                           \"telefono\": \"string\",\n",
    "                           \"correo_electronico\": \"string\",\n",
    "                           \"fecha\": \"string\",\n",
    "                           \"firma\": \"string\",\n",
    "                            \"sugerencia_tratamientos\": [tratamiento: \"string\", explicacion: \"string\"],\n",
    "                            \"sugerencia_farmacos\": [farmaco: \"string\", efecto: \"string\"],\n",
    "                            \"sugerencia_revision\": [frecuencia_revision: \"string\", explicacion: \"string\"],\n",
    "                       }.\"\"\")\n",
    "\n",
    "    try:\n",
    "        base64_image = encode_image(image)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {my_api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "            return response_data['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return \"Error: No valid response from GPT-4.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during GPT-4 image processing: {e}\"\n",
    "\n",
    "# Function to process and combine images and pass to GPT\n",
    "def process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return images, []\n",
    "\n",
    "    combined_image = combine_images(images, orientation)\n",
    "\n",
    "    # Send combined image to GPT-4\n",
    "    marked_fields = send_image_to_gpt(combined_image, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    if \"Error\" in marked_fields:\n",
    "        return marked_fields, []\n",
    "\n",
    "    return marked_fields, [combined_image]\n",
    "\n",
    "# Function to display images\n",
    "def show_images(pdf_file_path):\n",
    "    images = convert_pdf_to_images(pdf_file_path)\n",
    "    if isinstance(images, str) and images.startswith(\"Error\"):\n",
    "        return []\n",
    "    return images\n",
    "\n",
    "# Function to save extracted fields to a JSON file\n",
    "def save_to_json(extracted_fields):\n",
    "    try:\n",
    "        data = json.loads(extracted_fields)\n",
    "        json_file = \"extracted_data.json\"\n",
    "\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        return json_file\n",
    "    except Exception as e:\n",
    "        return f\"Error during JSON export: {e}\"\n",
    "\n",
    "# Function to save extracted fields to an EXCEL file\n",
    "def save_to_excel(extracted_fields, pdf_file_name):\n",
    "    try:\n",
    "        data = json.loads(extracted_fields)\n",
    "        df = pd.DataFrame([data])\n",
    "        df.insert(0, 'NOMBRE_ARCHIVO', pdf_file_name)\n",
    "        excel_file = \"extracted_data.xlsx\"\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        return excel_file\n",
    "    except Exception as e:\n",
    "        return f\"Error during Excel export: {e}\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "def interface_fn(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
    "    text_output, images = process_and_combine_images(pdf_file_path, orientation, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "    return text_output, images\n",
    "\n",
    "def show_images_fn(pdf_file_path):\n",
    "    images = show_images(pdf_file_path)\n",
    "    return gr.update(visible=True, value=images)\n",
    "\n",
    "def download_json_fn(extracted_fields):\n",
    "    json_file_path = save_to_json(extracted_fields)\n",
    "    if json_file_path.startswith(\"Error\"):\n",
    "        return gr.update(visible=True, label=json_file_path)\n",
    "    return json_file_path\n",
    "\n",
    "def download_excel_fn(extracted_fields, pdf_file_path):\n",
    "    pdf_file_name = os.path.basename(pdf_file_path)\n",
    "    excel_file_path = save_to_excel(extracted_fields, pdf_file_name)\n",
    "    if excel_file_path.startswith(\"Error\"):\n",
    "        return gr.update(visible=True, label=excel_file_path)\n",
    "    return excel_file_path\n",
    "\n",
    "def clear_fn():\n",
    "    return None, gr.update(visible=False), gr.update(visible=False)\n",
    "\n",
    "\n",
    "prompt_template_2 = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "model_2 = OpenAI(openai_api_key=openai.api_key, model_name=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=prompt_template_2, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(model_2, chain_type=\"stuff\", prompt=prompt_2)\n",
    "\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "\n",
    "Pregunta = \"\"\n",
    "\n",
    "db = FAISS.load_local(folder_path=\"/teamspace/studios/this_studio/Curso_IA_Gen/Formularios\",embeddings=embeddings,index_name=\"myFaissIndex\",allow_dangerous_deserialization=True)\n",
    "docs = db.similarity_search(Pregunta)\n",
    "\n",
    "response = chain(\n",
    "    {\"input_documents\": docs, \"question\": Pregunta}, return_only_outputs=True\n",
    ")\n",
    "\n",
    "def responder_cie(Pregunta):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    db = FAISS.load_local(folder_path=\"/teamspace/studios/this_studio/Curso_IA_Gen/Formularios\",embeddings=embeddings,index_name=\"myFaissIndex\",allow_dangerous_deserialization=True)\n",
    "    docs = db.similarity_search(Pregunta)\n",
    "    response = chain({\"input_documents\": docs, \"question\": Pregunta})\n",
    "        \n",
    "    return response['output_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "css = \"\"\"\n",
    "#fixed-pdf-input {\n",
    "    width: 100%;  /* Set the desired width */\n",
    "    height: 300px;  /* Set the desired height */\n",
    "    overflow: hidden;  /* Hide any overflowing content */\n",
    "    border: 1px solid #ccc;  /* Optional: Add a border */\n",
    "    padding: 10px;  /* Optional: Add padding */\n",
    "    box-sizing: border-box;  /* Ensure padding and border are included in the width and height */\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://5d3bcd851e54501861.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5d3bcd851e54501861.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-fbswhhr7 because the default path (/teamspace/studios/this_studio/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css=css, theme=gr.themes.Default(primary_hue=gr.themes.colors.indigo).set(button_primary_background_fill=\"*primary_400\")) as interface:\n",
    "    with gr.Tab(\"Procesador PDF\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Extractor de Datos desde Archivos PDF\n",
    "            Cargue un PDF para extraer e identificar las casillas marcadas mediante OCR y GPT-4. \n",
    "            Haga clic en «Enviar» para extraer los campos y en «Mostrar Imágenes» para mostrar las páginas PDF.\n",
    "            \"\"\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                pdf_input = gr.File(type=\"filepath\", label=\"Cargar PDF\", elem_id=\"fixed-pdf-input\")\n",
    "                orientation = gr.Dropdown([\"vertical\", \"horizontal\"], label=\"Orientación\")\n",
    "                submit_button = gr.Button(\"Enviar\", variant=\"primary\")\n",
    "                clear_button = gr.Button(\"Limpiar\")\n",
    "            with gr.Column():\n",
    "                text_output = gr.Textbox(label=\"Campos Extraídos\", placeholder=\"La información extraída aparecerá aquí...\", lines=23)\n",
    "        \n",
    "        image_gallery = gr.Gallery(label=\"Páginas PDF\", visible=True)\n",
    "        show_images_button = gr.Button(\"Mostrar Imágenes\", visible=True)\n",
    "        \n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Asistente virtual\n",
    "            Compruebe los códigos CIE-10 y devuelve la última versión publicada por la OMS\n",
    "            \"\"\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            inputs = gr.Textbox(label=\"Pregunta\", lines=5)\n",
    "            outputs = gr.Textbox(label=\"Respuesta\", lines=5)\n",
    "        with gr.Row():\n",
    "            enviar_button = gr.Button(\"Enviar\", variant=\"primary\")\n",
    "            clear_button2 = gr.Button(\"Limpiar\")\n",
    "        \n",
    "        enviar_button.click(fn=responder_cie, inputs=[inputs], outputs=[outputs])\n",
    "        clear_button2.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible=True)), outputs=[outputs])\n",
    "        \n",
    "        with gr.Row():\n",
    "            download_json_button = gr.Button(\"Descargar en JSON\", visible=True)\n",
    "            download_excel_button = gr.Button(\"Descargar en Excel\", variant=\"primary\")\n",
    "\n",
    "        # State variables for configuration\n",
    "        model_state = gr.State(default_config[\"model\"])\n",
    "        temperature_state = gr.State(default_config[\"temperature\"])\n",
    "        max_tokens_state = gr.State(default_config[\"max_tokens\"])\n",
    "        top_p_state = gr.State(default_config[\"top_p\"])\n",
    "        frequency_penalty_state = gr.State(default_config[\"frequency_penalty\"])\n",
    "        presence_penalty_state = gr.State(default_config[\"presence_penalty\"])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=interface_fn, \n",
    "            inputs=[pdf_input, orientation, model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state],\n",
    "            outputs=[text_output, image_gallery]\n",
    "        )\n",
    "        show_images_button.click(fn=show_images_fn, inputs=pdf_input, outputs=image_gallery)\n",
    "        clear_button.click(fn=lambda: (None, gr.update(visible=True), gr.update(visible=True)), outputs=[text_output, show_images_button, image_gallery])\n",
    "        download_json_button.click(fn=download_json_fn, inputs=[text_output], outputs=[gr.File()])\n",
    "        download_excel_button.click(fn=download_excel_fn, inputs=[text_output, pdf_input], outputs=[gr.File()])\n",
    "\n",
    "    with gr.Tab(\"Configuration\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Configuration Settings\n",
    "            Adjust the GPT-4 parameters to fine-tune the extraction process.\n",
    "            \"\"\"\n",
    "        )\n",
    "        model = gr.Textbox(value=default_config[\"model\"], label=\"Model\")\n",
    "        temperature = gr.Slider(0.0, 1.0, value=default_config[\"temperature\"], step=0.1, label=\"Temperature\")\n",
    "        max_tokens = gr.Slider(10, 4000, value=default_config[\"max_tokens\"], step=50, label=\"Max Tokens\")\n",
    "        top_p = gr.Slider(0.0, 1.0, value=default_config[\"top_p\"], step=0.1, label=\"Top P\")\n",
    "        frequency_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"frequency_penalty\"], step=0.1, label=\"Frequency Penalty\")\n",
    "        presence_penalty = gr.Slider(-2.0, 2.0, value=default_config[\"presence_penalty\"], step=0.1, label=\"Presence Penalty\")\n",
    "\n",
    "        save_button = gr.Button(\"Save Settings\")\n",
    "        \n",
    "        save_button.click(\n",
    "            fn=lambda model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty: (model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty),\n",
    "            inputs=[model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty],\n",
    "            outputs=[model_state, temperature_state, max_tokens_state, top_p_state, frequency_penalty_state, presence_penalty_state]\n",
    "        )\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
